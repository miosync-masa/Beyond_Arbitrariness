# Beyond Arbitrariness: Universal Body–Sound Mapping Across 11,540 Language Varieties

**Authors:** Masamichi Iizumi¹

**Affiliation:** ¹Miosync, Inc.

**Classification:** Social Sciences — Linguistics / Biological Sciences — Cognitive Sciences

**Keywords:** sound symbolism, language universals, articulatory phonetics, Saussurean arbitrariness, environmental adaptation

---

## Significance Statement

For over a century, the arbitrary relationship between sound and meaning has been a foundational axiom of linguistics. Analyzing 2.38 million phonemes across 11,540 language varieties (389 families), we show that articulatory features systematically align with semantic categories: "big" is spoken with an open mouth and "small" with a closed mouth across the vast majority of language families worldwide. A latitude gradient in word-final vowel frequency (71.3% tropical → 41.6% subarctic, family-level d = 1.09; replicated in Lexibank at d = 1.49) is consistent with environmental modulation of surface phonology. Linking this to Grambank grammatical features across 2,000+ languages, we find that phonotactic geometry predicts morphological strategy — not complexity, but positional allocation of affixes. These findings propose a candidate mechanism (Thought→Body→Sound) for the biases documented by Blasi et al. (2016) and reframe cross-linguistic variation as constrained optimization over a shared deep structure.

---

## 1. Introduction

The principle that the relationship between linguistic sign and meaning is arbitrary has served as a foundational axiom of modern linguistics since Saussure (1916). Hockett (1960) formalized arbitrariness as one of the design features of human language, and the assumption has guided a century of linguistic theory.

Challenges to pure arbitrariness have accumulated steadily. Sound symbolism research has documented non-arbitrary associations in controlled experiments (Sapir 1929; Köhler 1929; Ramachandran & Hubbard 2001), in individual languages through ideophones and phonesthemes (Dingemanse 2012; Bergen 2004), and in experimental iconicity paradigms (Perlman & Lupyan 2018; Winter et al. 2017). Most recently, at typological scale, Blasi et al. (2016), analyzing word lists covering approximately two-thirds of the world's languages, demonstrated that a considerable proportion of 100 basic vocabulary items carry strong associations with specific speech sounds, occurring persistently across continents and linguistic lineages. Words for "tongue" tend to contain /l/, "nose" tends toward /n/, and "small" associates with /i/.

These findings established the empirical reality of cross-linguistic sound–meaning biases beyond reasonable doubt. However, the authors noted that the patterns "could potentially have derived from sound symbolic associations (or a related phenomenon)" — the causal mechanism remained unspecified.

The present study addresses this gap. We propose a framework — Thought→Body→Sound (TBS) — in which the universal human articulatory apparatus, given universal cognitive-emotional structures, generates predictable and systematic mappings from meaning categories to phonological features. We provide five forms of evidence:

1. **Multi-dimensional articulatory profiles** for 100 basic concepts across 11,540 language varieties, showing that mouth openness, voicing, consonant sonority, and place of articulation simultaneously align with meaning in ways predicted by articulatory physics.

2. **Phylogenetic and permutation controls** demonstrating that these patterns are not artifacts of language family size, areal contact, or data structure.

3. **A latitude gradient** in phonological parameters consistent with environmental adaptation of surface features over an invariant deep mapping — paralleling the well-documented latitude gradient in human skin pigmentation — including a 29.6-percentage-point decrease in word-final vowel frequency from tropical to subarctic languages (family-level d = 1.09).

4. **External replication** using the independently collected Lexibank database (5,478 languages, 1.71 million forms, IPA transcription), confirming 92% of directional predictions and replicating the word-final gradient with a larger effect size (d = 1.49).

5. **A phonotactic–morphological coupling** demonstrated by linking word-final vowel frequency to grammatical features primarily from Grambank (Skirgård et al. 2023; 2,251 languages), with supplementary data from WALS, revealing that word-final phonotactic geometry predicts not the *amount* of morphology a language possesses but its *distributional strategy* — specifically, a systematic trade-off between prefixal and suffixal person marking.

We do not argue that arbitrariness is false. Lexical labels are largely arbitrary at the individual word level. Rather, we demonstrate that beneath the arbitrary surface, a non-arbitrary Thought→Body→Sound mapping operates as a systematic substrate, shaping not only the phonological form of basic vocabulary but, through cascading phonotactic constraints, the morphological strategies available across the vast majority of documented language families.

---

## 2. Theoretical Framework

### 2.1 From Statistical Bias to Candidate Mechanism

Blasi et al. (2016) established that sound–meaning associations exist at scale. The present framework asks *why* they exist, and proposes a candidate causal chain grounded in articulatory physics:

**Thought → Body → Sound**

The logic is as follows. All Homo sapiens share:
- An identical articulatory apparatus (lips, tongue, velum, larynx, nasal cavity)
- Equivalent cognitive and emotional architecture for basic concepts (body parts, kin, elements, life/death)

Given identical "hardware" and equivalent "input," the TBS framework predicts that the mapping from concept to phonological form should exhibit systematic regularities — not at the level of individual lexical items, but at the level of articulatory features aggregated across the lexicon.

Specifically:
- Concepts involving a particular body part should preferentially recruit sounds produced *by* that body part (the **self-naming hypothesis**)
- Concepts with shared semantic features (size, animacy, material hardness) should recruit sounds with shared articulatory features (openness, voicing, sonority)
- These mappings should appear across genetically unrelated language families, since they arise from shared biology rather than shared ancestry

### 2.2 Environmental Adaptation of Surface Parameters: A Structural Parallel

A potential objection is that cross-linguistic regularities might reflect common ancestry rather than independent innovation. We address this through phylogenetic controls (Section 3), but also through a theoretical framing that clarifies the relationship between universal structure and observed variation.

Consider the well-documented relationship between latitude and human skin pigmentation (Jablonski & Chaplin 2000). The underlying biological structure — keratinocytes, melanocytes, collagen architecture — is invariant across all human populations. The surface parameter — melanin concentration — varies continuously with UV radiation intensity. No biologist interprets low melanin concentration as evidence of a fundamentally different skin structure. The variation is environmental adaptation of a surface parameter over an invariant deep structure.

We propose that the same mathematical structure applies to language phonology:

| Component | Pigmentation System | Language Phonology |
|-----------|--------------------|--------------------|
| **Invariant** (deep structure) | Skin cellular architecture | Thought→Body→Sound mapping |
| **Independent variable** (environment) | UV radiation intensity | Climate / temperature |
| **Dependent variable** (surface parameter) | Melanin concentration | Vowel ratio, mouth openness |
| **Adaptive mechanism** (physical cause) | UV protection requires increased melanin | Cold air avoidance favors closed-mouth articulation |
| **Observed gradient** | Equator → Poles: dark → light (r² = 0.77) | Tropics → Subarctic: 47.4% → 40.3% vowels |

This is more than a loose analogy; both systems exhibit environmental modulation of a continuous surface parameter over a biologically invariant deep structure, making the parallel instructive for generating predictions. Formally:

- Pigmentation: M(λ) = f(UV(λ)) + ε
- Phonology: V(λ) = g(T(λ)) + ε

where λ = latitude, and the deep structure (skin architecture; TBS mapping) is invariant across all λ.

The critical implication: just as variation in melanin concentration does not imply variation in skin structure, variation in phonological surface parameters does not imply variation in the underlying Thought→Body→Sound mapping. Languages are not separated at depth; they are differentiated at the surface.

The environmental–phonological coupling proposed here is consistent with prior findings. Everett, Blasi & Roberts (2015) demonstrated across approximately 3,700 languages that languages in drier climates preferentially use fewer vowels, attributing this to the effect of desiccated air on vocal fold vibration. Maddieson & Coupé (2015) reported additional correlations between ecological factors and phonological inventory size. Our latitude gradient data provide an independent confirmation along the temperature axis, and the word-final positional specificity reported in §4.11 adds a new dimension to this environmental–phonological relationship.

### 2.3 Relationship to Existing Theoretical Frameworks

The TBS framework is intended to complement, not replace, existing theoretical frameworks.

**Universal Grammar (Chomsky 1965).** Chomsky proposed that humans possess an innate language faculty with universal structural properties, primarily at the level of syntax. If UG demonstrates universality at the grammatical level, the present study demonstrates universality at the phonosemantic level. These may represent different layers of a single multi-layered universal language architecture.

**Linguistic Relativity (Sapir 1929; Whorf 1956).** The Sapir-Whorf hypothesis, in its strong form, proposes that language structure shapes or constrains thought. The TBS framework suggests a revision of the causal direction: shared thought and shared body produce shared phonological tendencies. Lexical variation across languages reflects variation in environmental necessity — which distinctions a community *needs* to encode — rather than variation in cognitive capacity. A language with fewer color terms reflects an ecology where fine-grained color distinction carries less survival value, not a population with reduced perceptual capacity. The causal arrow runs: Environment → Necessity → Lexicon, not Language → Cognition.

This reframing carries an important implication. The original Sapir-Whorf formulation, however unintentionally, permits a structural inference from linguistic difference to cognitive difference — from "their language lacks X" to "they cannot think X." Reversing the causal direction eliminates this inference: linguistic differences are environmental adaptations, not cognitive limitations.

We note that weaker versions of linguistic relativity — in which language influences but does not determine cognition (e.g., Wolff & Holmes 2011) — are not incompatible with the TBS framework. Language may indeed shape habitual attention and categorical perception without determining the bounds of thought. The present critique targets specifically the causal architecture of the strong form, in which linguistic structure is taken as evidence of cognitive structure. Our aim is not to adjudicate the relativity debate as such, but to specify a biologically grounded source of cross-linguistic regularities that is independent of the relativity question.

### 2.4 Articulatory Constraints as a Substrate for Higher-Level Structure

The TBS framework has implications beyond the lexicon. If environmental pressures systematically shape the phonological space available to a language, then higher-level structures — morphology and syntax — must be built on top of this constrained phonological substrate.

The logic proceeds as follows:

1. **Phonological inventory is environmentally constrained.** Climate, altitude, and subsistence patterns shape which sounds are articulatorily favored, how words typically end, and what consonant clusters are tolerated.

2. **Word-final phonotactics define the morphological "slot geometry."** The terminal segment of a word is morphologically privileged: it determines what can attach at the word boundary. A vowel-final language offers a "soft slot" — open, accessible, amenable to vocalic suffixes. A consonant-final language offers a "closed-stack slot" — amenable to consonant-chain suffixation but resistant to vocalic attachment. These are not quantitative differences in morphological capacity; they are geometric differences in the available morphological space.

3. **Morphological strategy redistributes under constraint.** The critical prediction is not that morphology simplifies under phonological pressure, but that it *reallocates*. When environmental pressure closes word-final slots, languages do not lose morphological complexity — they reorganize it: shifting between prefixal and suffixal strategies, developing case systems, or compensating through syntactic means (Sapir 1921; Greenberg 1963).

This yields a causal chain that extends the TBS framework upward through the linguistic hierarchy — not as a gradient of simplification, but as a branching of optimization strategies:

Environment → Articulatory constraint → Phonotactic geometry → Morphological strategy reallocation → Syntactic compensation → Typological classification

If this chain holds, then what historical linguistics has classified as "language types" (isolating, agglutinating, fusional) may partly reflect different optimization paths under different environmental-articulatory constraints, rather than fundamentally different linguistic architectures. The phylogenetic tree of languages, on this view, records not the divergence of deep structures but the differential adaptation of surface strategies — precisely as the melanin parallel predicts.

We term this extended framework the **Universal Articulatory Substrate (UAS)**: the proposition that phonological constraints arising from the shared human articulatory apparatus, modulated by environment, form the foundation upon which all higher-level linguistic structure is constructed. UAS does not replace Universal Grammar; it proposes a layer beneath it. If UG specifies the structural possibilities of syntax, UAS specifies the phonological-articulatory ground from which those possibilities are realized.

---

## 3. Data and Methods

### 3.1 Data Source

We use the Automated Similarity Judgment Program (ASJP) Database v21 (Wichmann et al. 2022), accessed via the Cross-Linguistic Data Formats (CLDF) interface (Forkel et al. 2018). The database contains:

- 11,540 language varieties
- 389 language families (plus isolates)
- 566,435 word forms (after excluding forms marked as loans)
- 2,379,766 individual phonemes
- 100 basic vocabulary concepts (Swadesh-type list)

ASJP uses a standardized phonological transcription system (ASJPcode) with 34 consonant symbols and 7 vowel symbols, representing major phonological contrasts while abstracting over fine phonetic detail. While coarser than IPA transcription, this system has been validated for large-scale typological analysis (Wichmann et al. 2010; Blasi et al. 2016).

### 3.2 Articulatory Feature System

We assign articulatory features to each ASJPcode symbol along four dimensions:

**Vowels:**
- Openness (mouth aperture): close = 1, close-mid = 2, mid = 2.5, open-mid = 3, open = 4

**Consonants:**
- Place of articulation: labial = 1.0, dental = 2.0, alveolar = 2.5, postalveolar = 3.0, retroflex = 3.2, palatal = 3.5, velar = 4.0, uvular = 4.5, glottal = 5.0
- Voicing: voiced = 1, voiceless = 0
- Sonority: stops = 1–2, fricatives = 3–4, nasals = 6, liquids/approximants = 7

For each word form, we compute the mean value of each dimension across all phonemes in the word, yielding a 4-dimensional articulatory profile per word.

### 3.3 Analysis Pipeline

For each of the 100 concepts:

1. Compute the mean articulatory profile (openness, voicing, sonority, place) across all word forms for that concept
2. Compare against the global baseline (mean across all concepts) using Welch's t-test
3. Compute Cohen's d effect size
4. Apply Benjamini-Hochberg FDR correction across all 400 tests (100 concepts × 4 dimensions)

### 3.4 Statistical Controls

**Phylogenetic control.** To ensure that patterns are not driven by large language families, we aggregate data at the family level: for each concept × family combination, we compute the family-level mean, then compare across families (each family = one data point). We report both language-level and family-level statistics.

**Permutation test.** To test whether observed patterns are concept-specific rather than artifacts of data structure, we randomly shuffle concept labels across word forms 10,000 times and compare the observed deviation to the permutation distribution.

**Multiple testing.** We apply Benjamini-Hochberg FDR correction at α = 0.05 across all 400 hypothesis tests.

**Inter-dimension correlation.** The four articulatory dimensions are not fully independent. We compute the 4×4 Pearson correlation matrix across all 558,053 word-level observations and apply the Nyholt (2004) eigenvalue-based correction to estimate the effective number of independent dimensions (M_eff). Joint p-values for multi-dimensional predictions are adjusted accordingly.

**Areal control.** ASJP excludes forms marked as loans. Additionally, our phylogenetic control (family-level analysis) mitigates areal diffusion effects, since geographically proximate languages from the same family are collapsed into a single data point.

---

## 4. Results

### 4.1 Overall Significance

Of 400 concept × dimension tests, 336 (84.0%) are significant after FDR correction at α = 0.05, and 298 (74.5%) at α = 0.001. This far exceeds chance expectation (5% under H₀) and confirms pervasive, systematic deviation of concept-level articulatory profiles from the global baseline.

### 4.2 Body Part Self-Naming

Body parts show systematic preference for sounds produced by the relevant articulatory organ:

| Body part | Predicted feature | Observed | Global baseline | Cohen's d | p (FDR) |
|-----------|------------------|----------|-----------------|-----------|---------|
| TONGUE | High sonority (lateral/trill) | 4.65 | 3.95 | +0.41 | < 10⁻³⁰⁰ |
| TONGUE | Alveolar place (tongue-tip) | 52.1% | 42.0% | — | < 10⁻³⁰⁰ |
| NOSE | High sonority (nasal) | 4.28 | 3.95 | +0.20 | < 10⁻³⁰⁰ |
| NOSE | Closed mouth (low openness) | 1.98 | 2.30 | −0.33 | < 10⁻³⁰⁰ |
| MOUTH | Labial place (lip sounds) | 30.2% | 23.0% | — | < 10⁻³⁰⁰ |

The tongue names itself with tongue-tip sounds. The nose names itself with nasal sounds produced while the mouth is closed. The mouth names itself with lip sounds. These patterns are consistent with the self-naming hypothesis: the articulatory organ that produces the sound is the same organ being named.

### 4.3 Semantic Size and Mouth Openness

| Concept | Mean openness | Δ from baseline | Cohen's d | p (FDR) |
|---------|--------------|-----------------|-----------|---------|
| BIG | 2.438 | +0.141 | +0.146 | 1.3 × 10⁻¹⁴ |
| LONG | 2.450 | +0.153 | +0.164 | < 10⁻³⁰⁰ |
| KILL | 2.448 | +0.153 | +0.158 | 7.9 × 10⁻¹⁵ |
| — baseline — | 2.297 | — | — | — |
| SMALL | 2.164 | −0.127 | −0.131 | 3.4 × 10⁻¹⁴ |
| NOSE | 1.983 | −0.314 | −0.325 | < 10⁻³⁰⁰ |
| KNEE | 1.941 | −0.356 | — | < 10⁻³⁰⁰ |

"Big" is spoken with an open mouth; "small" with a closed mouth. This pattern extends beyond the classic /a/~/i/ vowel contrast to the full articulatory profile of the word.

### 4.4 Voicing and Animacy

| Concept | Voiced % | Δ from baseline | Cohen's d | p (FDR) |
|---------|----------|-----------------|-----------|---------|
| I (self) | 72.6% | +12.6% | +0.405 | < 10⁻³⁰⁰ |
| TONGUE | 71.3% | +11.3% | +0.370 | < 10⁻³⁰⁰ |
| NAME | 71.9% | +11.9% | — | < 10⁻³⁰⁰ |
| MAN | 70.7% | +10.7% | — | < 10⁻³⁰⁰ |
| — baseline — | 59.7% | — | — | — |
| BONE | 49.5% | −10.6% | −0.330 | < 10⁻³⁰⁰ |
| BARK | 49.4% | −10.6% | — | < 10⁻³⁰⁰ |
| LOUSE | 49.1% | −10.9% | — | < 10⁻³⁰⁰ |

Living, animate, or self-referential concepts are named with voiced sounds (vocal cord vibration); hard, inanimate objects with voiceless sounds. The first person pronoun "I" shows the highest voicing ratio of any concept tested — the self is named with the most resonant sound the body can produce.

### 4.5 Sonority and Material Properties

| Concept | Mean sonority | Δ | Cohen's d | p (FDR) |
|---------|--------------|---|-----------|---------|
| I | 4.70 | +0.75 | +0.44 | < 10⁻³⁰⁰ |
| TONGUE | 4.65 | +0.70 | +0.41 | < 10⁻³⁰⁰ |
| NAME | 4.63 | +0.68 | — | < 10⁻³⁰⁰ |
| WATER | 4.21 | +0.26 | +0.15 | < 10⁻³⁰⁰ |
| — baseline — | 3.95 | — | — | — |
| STONE | 3.49 | −0.46 | −0.27 | < 10⁻³⁰⁰ |
| BONE | 3.39 | −0.57 | −0.33 | < 10⁻³⁰⁰ |
| BARK | 3.25 | −0.70 | — | < 10⁻³⁰⁰ |

Soft, flowing, or living concepts are named with sonorant sounds (nasals, liquids); hard, rigid objects with obstruent sounds (stops, fricatives). Water flows with flowing sounds; stone stops with stopping sounds.

### 4.6 Multi-Dimensional Coherence

Individual effect sizes are small (Cohen's d typically 0.05–0.30), as expected given that each word carries a small meaning-signal diluted by large phonological noise. However, for key concepts, multiple articulatory dimensions deviate from the baseline *simultaneously and in the predicted direction*.

**Inter-dimension correlation.** The four dimensions are not fully independent. The strongest correlation is between voicing and sonority (r = +0.748), which is expected since voiced consonants tend to be more sonorant by definition. Openness is nearly independent of the other three dimensions (r < 0.07). Eigenvalue analysis of the 4×4 correlation matrix yields an effective number of independent dimensions M_eff = 3.72 (Nyholt 2004).

**Joint significance.** For each concept with multi-dimensional predictions, we compute the joint probability that all predicted deviations occur simultaneously, with correction for inter-dimension correlation (K_eff = K × M_eff/M):

| Concept | Predicted dims (K) | K_eff | All match? | p_joint (corrected) |
|---------|-------------------|-------|------------|---------------------|
| BIG | open↑ voiced↑ sonority↓ (3) | 2.79 | Yes (3/3) | 7.1 × 10⁻²⁷ |
| SMALL | open↓ voiced↓ sonority↓ (3) | 2.79 | Yes (3/3) | < 10⁻⁸⁰⁰ |
| LONG | open↑ voiced↑ sonority↑ (3) | 2.79 | Yes (3/3) | < 10⁻²⁹⁰ |
| I | voiced↑ sonority↑ (2) | 1.86 | Yes (2/2) | < 10⁻⁵⁵⁰ |
| TONGUE | voiced↑ sonority↑ (2) | 1.86 | Yes (2/2) | < 10⁻⁵⁵⁰ |
| BONE | voiced↓ sonority↓ (2) | 1.86 | Yes (2/2) | < 10⁻⁵⁵⁰ |
| DIE | voiced↓ sonority↓ (2) | 1.86 | Yes (2/2) | < 10⁻²⁹⁰ |
| WATER | voiced↑ sonority↑ (2) | 1.86 | Yes (2/2) | < 10⁻⁵⁵⁰ |
| STONE | voiced↓ sonority↓ (2) | 1.86 | Yes (2/2) | < 10⁻⁵⁵⁰ |

Across 11 tested concepts, the predicted direction matches the observed direction in **100% of cases** (24/24 dimension-predictions). Even with the most conservative correlation correction, joint p-values remain below 10⁻²⁷.

### 4.7 Semantic Category Profiles

Aggregating concepts into semantic categories reveals systematic articulatory "signatures":

| Category | Concepts | Openness | Sonority | Voicing | Profile |
|----------|----------|----------|----------|---------|---------|
| Active movement | swim, fly, walk, come | +0.19 | +0.23 | +0.048 | OPEN + SOFT + VOICED |
| Earth/mineral | stone, sand, soil | +0.10 | −0.36 | −0.055 | OPEN + HARD + VOICELESS |
| Water | water, rain | −0.04 | +0.26 | +0.074 | SOFT + VOICED |
| Body (oral) | mouth, tongue, tooth | −0.05 | +0.41 | +0.062 | SOFT + VOICED |
| Size (big) | big | +0.14 | −0.25 | +0.037 | OPEN + HARD + VOICED |
| Size (small) | small | −0.13 | −0.46 | −0.087 | CLOSED + HARD + VOICELESS |
| Death | die | +0.06 | −0.13 | −0.050 | HARD + VOICELESS |

These profiles exhibit systematic symmetry: active/living/flowing concepts recruit voiced, sonorant sounds; rigid/dead/static concepts recruit voiceless stops. This coherence across independent semantic domains is difficult to explain as coincidence.

### 4.8 Phylogenetic Control

When each language family is treated as a single data point (family-level mean), all major patterns survive:

| Comparison | N families | Cohen's d | p |
|------------|-----------|-----------|---|
| I vs BONE (voicing) | 362 | 0.74 | < 10⁻²⁰ |
| TONGUE vs BONE (sonority) | 366 | 0.51 | 3.6 × 10⁻¹² |
| BIG vs SMALL (openness) | 241 | 0.31 | 8.0 × 10⁻⁴ |
| WATER vs STONE (voicing) | 372 | 0.22 | 2.6 × 10⁻³ |

Notably, the family-level effect size for I vs BONE (d = 0.74) qualifies as a "medium-to-large" effect by conventional standards. The patterns are not driven by a few large language families but are distributed across hundreds of independent lineages.

### 4.9 Permutation Test

Randomly shuffling concept labels across word forms (10,000 permutations) yields a null distribution against which observed deviations can be tested:

| Comparison | Observed Δ | Permutations exceeding | p |
|------------|-----------|----------------------|---|
| BIG vs SMALL (openness) | +0.268 | 0 / 10,000 | < 0.0001 |
| I vs BONE (voicing) | +0.274 | 0 / 10,000 | < 0.0001 |
| TONGUE vs BONE (sonority) | +1.270 | 0 / 10,000 | < 0.0001 |

In no case did a random permutation produce a deviation as large as the observed value.

### 4.10 Latitude Gradient

Phonological parameters vary systematically with latitude, consistent with environmental adaptation:

| Latitude band | Vowel % | Open/close ratio | Nasal % | N phonemes |
|--------------|---------|------------------|---------|------------|
| Tropical (0–15°) | 47.4% | 1.18 | 13.6% | 1,447,132 |
| Subtropical (15–30°) | 44.9% | 1.07 | 14.1% | 549,611 |
| Temperate (30–50°) | 43.0% | 1.15 | 11.1% | 278,353 |
| Subarctic (50–70°) | 40.3% | 1.16 | 11.2% | 81,154 |

Vowel percentage decreases by 7.1 percentage points from tropical to subarctic regions. This is consistent with the hypothesis that cold air intake during speech may favor closed-mouth articulation, as proposed for related environmental–phonological correlations by Everett, Blasi & Roberts (2015). The gradient suggests that surface phonological parameters respond to environmental pressure while the underlying body–sound mapping remains constant — the structure predicted by the TBS framework.

### 4.11 Word-Final Vowel Gradient: Evidence for Positional Environmental Pressure

The latitude gradient in overall vowel frequency (§4.10) raises a further question: does environmental pressure affect all positions within a word equally, or does it concentrate at word boundaries?

Analysis of word-final phonemes reveals a dramatically amplified gradient:

| Latitude band | N words | V-final % | C-final % |
|--------------|---------|-----------|-----------|
| Tropical (0–15°) | 339,941 | 71.3% | 28.7% |
| Subtropical (15–30°) | 136,410 | 61.3% | 38.7% |
| Temperate (30–50°) | 66,201 | 53.0% | 47.0% |
| Subarctic (50–70°) | 17,856 | 41.6% | 58.4% |

The word-final vowel rate drops by 29.6 percentage points from tropical to subarctic — more than four times the overall vowel gradient (7.1 points). The effect concentrates at word-final position: word-initial vowel rates show minimal latitude variation (20.4% tropical vs. 16.2% subarctic, Δ = 4.2 points).

Among individual phonemes at word-final position, open /a/ shows the steepest decline (20.7% → 10.0%), consistent with the prediction that the most open-mouth vowel is most disfavored in cold climates. Conversely, word-final consonants /s/, /n/, and /t/ — all produced with the mouth relatively closed — increase substantially in subarctic languages.

**Family-level control.** Aggregating by language family (each family = one data point), the tropical–subarctic difference remains large and significant:

| Band | N families | Mean V-final % | SD |
|------|-----------|----------------|-----|
| Tropical (0–15°) | 275 | 70.5% | 23.9% |
| Subarctic (50–70°) | 24 | 44.6% | 22.5% |

Welch's t = 5.39, p = 7.2 × 10⁻⁸, Cohen's d = 1.09. Bootstrap resampling (10,000 iterations) yields a 95% CI for Cohen's d of [0.67, 1.51], confirming the robustness of the effect despite the smaller subarctic sample. (The subarctic sample of 24 families reflects the geographic reality that fewer language families inhabit high latitudes, not a sampling limitation; Lexibank replication yields d = 1.49, 95% CI [1.03, 1.89]; see §4.12.)

This is the largest effect size observed in the present study, and it survives both phylogenetic control and independent replication.

**Final consonant clusters.** Cold-climate languages also show increased tolerance for word-final consonant clusters: the proportion of words ending in two or more consonants rises from 1.5% (tropical) to 11.9% (subarctic), an eightfold increase.

**Morphological implications.** Word-final position is precisely where inflectional suffixes typically reside across the world's languages. A systematic environmental shift in word-final phonotactics does not merely change word-ending sounds — it reshapes the "slot geometry" available for morphological operations. This observation motivates the analysis in §4.13, where we test whether word-final vowel frequency predicts the *distributional strategy* of morphology across languages.

### 4.12 External Validation: Lexibank Replication

To ensure that the findings reported above are not artifacts of the ASJP transcription system (ASJPcode, 41 symbols), we replicated all key analyses using the Lexibank database (List et al. 2022): 5,478 languages, 1.71 million word forms, transcribed in IPA — a fully independent dataset with a fundamentally different transcription methodology.

**Sound–meaning mapping.** Of 25 directional predictions derived from the ASJP analysis, 23 replicated in Lexibank (92.0% replication rate). Key effects replicated with comparable or larger effect sizes: I-voicing (d = +0.51 Lexibank vs. +0.41 ASJP), TONGUE-sonority (d = +0.56 vs. +0.41), SMALL-openness (d = −0.27 vs. −0.13), NOSE-openness (d = −0.45 vs. −0.33).

**Word-final vowel latitude gradient.** The gradient replicated with an even steeper slope:

| Latitude band | ASJP V-final % | Lexibank V-final % |
|--------------|----------------|---------------------|
| Tropical (0–15°) | 71.3% | 76.6% |
| Subtropical (15–30°) | 61.3% | 64.3% |
| Temperate (30–50°) | 53.0% | 49.7% |
| Subarctic (50–70°) | 41.6% | 42.9% |

Lexibank Δ = 33.7 percentage points (ASJP: 29.6). Family-level: Welch's t = 7.35, p = 1.9 × 10⁻¹³, Cohen's d = 1.49 (ASJP: d = 1.09). The word-final effect concentrates at final position in Lexibank as in ASJP: initial vowel rates show minimal latitude variation (21.3% → 15.8%).

These replications confirm that the TBS mapping, the latitude gradient, and the word-final positional effect are robust across independently collected datasets and transcription systems.

### 4.13 The Phonotactic–Morphological Cascade: Evidence from Grambank and WALS

The UAS framework (§2.4) predicts that word-final phonotactic structure should correlate with morphological strategy. We tested this by linking ASJP word-final vowel percentages (per language, via Glottocode) to grammatical features from Grambank (Skirgård et al. 2023; 2,251 overlapping languages).

**Feature selection and multiple comparison correction.** We selected 17 Grambank features on theoretical grounds prior to analysis: all binary features related to affixation type (prefix/suffix for person marking, non-person verb morphology), inflectional categories (tense, aspect, case), and basic word order — the domains where word-final phonotactics would most plausibly exert constraint. All 17 features were tested; p-values were corrected using the Benjamini-Hochberg FDR procedure. Of the 17 features, 9 survived FDR correction at α = 0.05. The 8 features reported in the table below all remain significant after correction. WALS features (26A Suffixation, 22A Synthesis, 49A Cases, 81A Word Order) were tested as supplementary checks; none reached significance (see discussion below), consistent with the coarser categorical coding of WALS relative to Grambank's binary features.

**The data do not support a simple "vowel loss → morphological simplification" narrative.** Instead, they reveal a systematic *reallocation* of morphological strategy:

| Grambank feature | n | r | p (raw) | p (FDR) | Direction |
|-----------------|---|---|---------|---------|-----------|
| A-argument **suffix** (GB091) | 2,110 | −0.116 | 8.0 × 10⁻⁸ | 1.4 × 10⁻⁶ | V-final ↑ → suffix *absent* |
| Verb suffixes, non-person (GB080) | 2,071 | +0.091 | 3.2 × 10⁻⁵ | 2.7 × 10⁻⁴ | V-final ↑ → suffix present |
| A-argument **prefix** (GB092) | 2,126 | +0.088 | 5.1 × 10⁻⁵ | 2.9 × 10⁻⁴ | V-final ↑ → prefix present |
| S-argument **suffix** (GB089) | 2,117 | −0.085 | 9.0 × 10⁻⁵ | 3.8 × 10⁻⁴ | V-final ↑ → suffix *absent* |
| S-argument **prefix** (GB090) | 2,126 | +0.078 | 3.1 × 10⁻⁴ | 1.1 × 10⁻³ | V-final ↑ → prefix present |
| Future tense marking (GB084) | 2,078 | +0.078 | 3.8 × 10⁻⁴ | 1.1 × 10⁻³ | V-final ↑ → tense marking present |
| Noun plural marking (GB044) | 2,108 | +0.072 | 9.5 × 10⁻⁴ | 2.3 × 10⁻³ | V-final ↑ → plural present |
| Morphological case (GB070) | 2,073 | −0.053 | 0.015 | 0.029 | V-final ↑ → fewer cases |

The critical pattern is the **prefix–suffix mirror**: high-V-final languages (tropical phonotactic profile) tend to mark person arguments with *prefixes* while using the word-final vowel slot for non-person morphology (tense, number, aspect). Low-V-final languages (subarctic phonotactic profile) shift person marking to *suffixes* and develop richer case systems — a different optimization strategy over a different phonotactic geometry.

**WALS supplementary analysis.** WALS features showed directionally consistent but non-significant trends: suffixation index (26A, r = −0.06, p = 0.07), number of cases (49A, r = −0.09, p = 0.14), inflectional synthesis (22A, r = +0.03, p = 0.74). The non-significance likely reflects WALS's categorical coding (e.g., "strongly suffixing" vs. "weakly suffixing") which collapses the fine-grained prefix/suffix distinctions that drive the Grambank signal.

Effect sizes are modest (r ≈ 0.05–0.12), consistent with the expectation that phonotactic structure is one force among many shaping morphological typology. However, the effects are consistent in direction across multiple independent grammatical features, survive FDR correction, and the prefix–suffix trade-off achieves p_FDR = 10⁻⁴ to 10⁻⁶ — indicating a weak but systematic structural coupling between phonotactics and morphological alignment strategies.

This result is consistent with the UAS prediction: word-final phonotactic geometry does not determine the *amount* of morphology a language possesses, but it may predict the *distributional strategy* — how morphological operations are allocated across available positions in the word.

---

## 5. Discussion

### 5.1 A Causal Mechanism for Cross-Linguistic Sound–Meaning Biases

Blasi et al. (2016) established that sound–meaning associations are pervasive and persist across linguistic lineages and geographic areas. The present study proposes a candidate mechanism: the Thought→Body→Sound mapping, grounded in the physical constraints of the human articulatory apparatus.

The mechanism operates at multiple levels:
- **Direct physical causation** (self-naming): The tongue names itself with tongue-tip sounds because the tongue is the organ producing those sounds. This is not symbolism but physical identity.
- **Articulatory iconicity** (size–openness): "Big" recruits open-mouth articulation because mouth openness is the articulatory dimension most directly isomorphic to spatial magnitude. This extends Ohala's (1994) frequency code — linking vocal pitch to perceived size — to the articulatory domain: it is not only F0 but the entire vocal tract geometry that maps onto magnitude.
- **Phonation-animacy mapping** (voicing–life): Living entities are named with voiced sounds (vocal cord vibration); dead/inert objects with voiceless sounds. The vibrating vocal cords may serve as an embodied index of vitality.

### 5.2 Multi-Dimensional Coherence as Evidence Against Coincidence

A legitimate concern is that individual effect sizes are small. We address this directly.

Individual phonemes carry a small meaning-related signal embedded in a large amount of phonological noise (historical sound change, borrowing, analogical leveling, drift). Small individual effect sizes are therefore *expected* under the TBS hypothesis — the prediction is not that every word for "big" contains /a/, but that *on average, across hundreds of language families*, words for "big" show a slight but consistent preference for open-mouth articulation.

The critical evidence is not the magnitude of any single effect, but the **multi-dimensional coherence** of simultaneously small effects. BIG simultaneously shows elevated openness (p < 10⁻¹⁴), elevated voicing (p < 0.03), and reduced sonority (p < 10⁻¹²). After correcting for inter-dimension correlation (M_eff = 3.72), the joint probability that all three deviations occur in the predicted direction by chance is 7.1 × 10⁻²⁷.

Across 11 concepts with explicit multi-dimensional predictions, the predicted direction matches the observed direction in 24 out of 24 cases (100%). The probability of this outcome under random assignment is 2⁻²⁴ ≈ 6 × 10⁻⁸, before considering the magnitude of each individual effect.

### 5.3 Revisiting Linguistic Relativity

The Sapir-Whorf hypothesis, particularly in its strong form, proposes that language structure constrains cognition. A language with fewer color terms, for instance, has been argued to limit its speakers' color perception.

The TBS framework suggests an alternative interpretation. If the deep Thought→Body→Sound mapping is universal, then cross-linguistic lexical differences reflect not cognitive differences but differences in *environmental necessity*. A community that does not lexically distinguish 30 shades of green is not perceptually impoverished — it inhabits an ecology where such distinctions carry insufficient survival or communicative value to warrant dedicated lexical encoding.

This reframing is important because the original causal structure of linguistic relativity — Language → Cognition — structurally permits an inference from linguistic difference to cognitive difference. The reversed causal structure — Environment → Necessity → Lexicon — eliminates this inference. Linguistic differences become evidence of ecological adaptation, analogous to variation in skin pigmentation: different surface expression of an identical underlying structure.

We note that this critique addresses the *structural implications* of the hypothesis, not the intentions of its authors. Sapir and Whorf were dedicated to the empirical study of linguistic diversity, and the strong deterministic reading of their work has been extensively qualified in subsequent research (e.g., Gentner & Goldin-Meadow 2003). Nevertheless, the causal architecture of the original formulation carries implications that the TBS framework renders unnecessary.

### 5.4 From Phonology to Morphology: Reallocation, Not Simplification

The initial hypothesis motivating the cascade analysis was straightforward: if environmental pressure erodes word-final vowels, inflectional capacity should contract, and languages should compensate through syntactic rigidification. The data tell a more interesting story.

Word-final vowel frequency does not predict morphological *complexity* — it predicts morphological *strategy*. High-V-final languages and low-V-final languages are approximately equally morphologically complex, but they allocate their morphological resources differently. The prefix–suffix trade-off in person marking (§4.13) is the clearest signal: the same functional load (indexing the agent on the verb) is carried by prefixes in vowel-terminal phonologies and by suffixes in consonant-terminal phonologies.

This is not morphological degradation under phonological pressure. It is **constrained optimization**: the morphological system reorganizes to exploit the phonotactic geometry available to it. A vowel-final word offers a "soft" terminal slot — open, accessible to vocalic suffixation. A consonant-final word offers a "stacked" terminal slot — amenable to consonant-chain agglutination but resistant to vocalic attachment. Both geometries support rich morphology; they support *different kinds* of rich morphology.

The analogy to biological adaptation is precise. Melanin variation does not represent a gradient from "more skin" to "less skin" — it represents different optimization strategies for the same organ under different environmental pressures. Similarly, morphological variation does not represent a gradient from "more grammar" to "less grammar" — it represents different optimization strategies for the same communicative functions under different phonotactic constraints.

This reframing strengthens the UAS framework. If the phonotactic–morphological coupling were a simple degradation gradient, it would be vulnerable to the objection that correlation with latitude merely reflects shared history or areal contact. The reallocation pattern — where the same morphological function *switches position* in the word rather than disappearing — is harder to attribute to coincidence and more consistent with a genuine structural coupling between phonotactic geometry and morphological design.

**Effect size in context.** The individual correlations reported in §4.13 (r ≈ 0.05–0.12) are modest, explaining less than 1.5% of variance in any single grammatical feature. This is expected: phonotactic structure is one force among many shaping morphological typology, alongside historical contact, genealogical inheritance, and sociolinguistic factors, which together account for the vast majority of typological variation. However, the theoretical significance of these correlations lies not in their individual magnitude but in their directional consistency. The prefix–suffix mirror — where person-marking prefixes and person-marking suffixes show equal-magnitude, opposite-sign correlations with word-final vowel frequency — emerges independently across eight grammatical features, all in the direction predicted by the phonotactic geometry model. The probability of eight independent binary predictions aligning by chance is 2⁻⁸ ≈ 0.004. In a causal chain where each link is weak but directionally consistent, the chain as a whole provides stronger evidence than any individual link.

### 5.5 Phylogenetic Trees as Records of Surface Adaptation

Traditional comparative linguistics reconstructs language family trees based on systematic sound correspondences. Languages that share more correspondences are classified as more closely related, and the tree records a history of divergence from proto-languages.

The TBS/UAS framework does not dispute the validity of comparative reconstruction. It does, however, suggest a reinterpretation of what the tree represents.

If the deep Thought→Body→Sound mapping is universal and invariant, then what diverges across language families may not be solely the deep structure but also — and perhaps primarily — the surface parameters: which specific phonemes are used, how they combine, and how historical sound change has reshaped the inventory. The phylogenetic tree, on this view, records not only genealogical divergence but also *how surface articulation has drifted under different environmental and historical pressures*. In addition to tracking descent from proto-languages, the tree may partly reflect differential adaptation of surface strategies.

This is the melanin parallel (§2.2): a phylogenetic tree of human skin color would show geographic clustering and historical branching, but no biologist would interpret it as evidence that different populations possess fundamentally different skin structures. The tree records surface parameter history alongside genealogical descent.

To the extent that the TBS mapping is shared, languages may diverge less at depth than their surface variation suggests. Grammatical systems, in this view, emerge partly as higher-order optimizations over phonological substrates that are themselves environmentally constrained.

### 5.6 Limitations

**Transcription granularity.** The ASJP transcription system collapses phonetic detail that may be relevant to sound symbolism (e.g., aspiration, tone, vowel length). Finer-grained transcription databases, as they become available at comparable scale, would enable more precise analysis.

**Concept coverage.** The 100 Swadesh-type concepts represent basic vocabulary. Extension to abstract concepts, emotions, and culturally specific domains remains an important direction.

**Latitude gradient.** Our environmental analysis uses latitude as a proxy for climate. More precise modeling using temperature, humidity, and altitude data could refine the environmental adaptation component.

**Areal effects.** While we exclude marked loanwords and control for phylogenetic non-independence, subtle areal convergence in phonological systems may contribute to observed patterns. Future work should incorporate explicit spatial autocorrelation models.

**Effect size context.** Individual effect sizes, while statistically significant, are small in absolute terms. The TBS mapping is a weak but pervasive force, continuously counteracted by historical sound change. It shapes statistical tendencies, not deterministic outcomes.

**Scope of "universal."** We use "universal" throughout to denote a statistical tendency observed across the vast majority of language families — not a deterministic correspondence that holds in every word of every language. Individual lexical items can and do violate the general tendency; the claim is that the aggregate direction is non-random and articulatorily motivated.

### 5.7 Future Directions

**The articulatory cascade: syntactic correlates.** The present study documents phonotactic-to-morphological coupling (§4.13). The next stage — whether morphological strategy differences systematically predict syntactic organization (word order rigidity, analytical vs. synthetic constructions) — requires more fine-grained morphological typology data and controlled diachronic evidence. Integration with the World Atlas of Linguistic Structures (Dryer & Haspelmath 2013) at the level of individual syntactic features, rather than broad typological categories, is a priority.

**Diachronic validation.** The present evidence is synchronic. If the UAS model is correct, historical sound changes that shift word-final phonotactics should predict subsequent morphological reorganization within individual language families. Well-documented families with reconstructed proto-languages (Indo-European, Austronesian, Bantu) offer natural test cases.

**Sign languages.** If the TBS mapping reflects a general Thought→Body→Expression principle rather than a specifically vocal one, parallel patterns should appear in sign languages: "big" signed with expansive gestures, "small" with contracted ones. Preliminary evidence from sign language research is consistent with this prediction (Taub 2001), but systematic cross-linguistic comparison awaits.

**Infant vocalization.** Pre-linguistic babbling represents the articulatory system before environmental or cultural shaping. Analysis of babbling patterns across linguistic communities could provide a developmental baseline for the TBS mapping.

**Emotion phonetics.** Cross-linguistic analysis of emotional speech (anger → hard consonants; affection → soft nasals) may reveal parallel body–sound mappings in the prosodic domain.

---

## 6. Conclusion

We have presented evidence from 11,540 language varieties, 389 language families, and 2.38 million phonemes — replicated in an independent database of 5,478 languages with IPA transcription — that the relationship between sound and meaning in human language, while largely arbitrary at the lexical surface, is systematically constrained at depth by the physical properties of the human articulatory apparatus.

The Thought→Body→Sound framework proposes a candidate mechanism for the cross-linguistic sound–meaning biases documented by Blasi et al. (2016) and others: identical articulatory hardware, given equivalent cognitive input, generates predictable phonological tendencies that surface independently across unrelated language families worldwide.

The discovery of a large word-final vowel latitude gradient (d = 1.09 in ASJP, d = 1.49 in Lexibank) further reveals that environmental-articulatory pressure shapes not only which sounds languages use, but where they appear within words. Crucially, this phonotactic variation does not simplify morphology — it *redirects* it. Languages with different word-final phonotactics allocate the same morphological functions to different positions in the word, maintaining comparable complexity through different optimization strategies. We propose the Universal Articulatory Substrate (UAS) as a framework for understanding how phonological constraints, arising from the shared human body and modulated by environment, shape linguistic structure at every level — not as a gradient of degradation, but as a branching of optimization paths.

Cross-linguistic variation, viewed through this lens, is not evidence of fundamental linguistic diversity — the branching of an original unity into irreconcilable fragments — but constrained optimization of surface strategies over a shared deep structure. Languages are not separated at the level of body–sound mapping. They are differentiated at the surface while sharing a common articulatory foundation.

The data suggest that what the world's language families share may be more fundamental than what distinguishes them. The shared human body, given shared cognitive structures, generates a systematic phonosemantic substrate — modulated but not erased by millennia of independent history, migration, and environmental adaptation. Recognizing this shared foundation may contribute not only to linguistic theory, but to the broader human project of understanding across apparent difference.

---

## References

Austin, J. L. (1962). *How to do things with words.* Oxford University Press.

Bergen, B. K. (2004). The psychological reality of phonaesthemes. *Language*, 80, 290–311.

Blasi, D. E., Wichmann, S., Hammarström, H., Stadler, P. F., & Christiansen, M. H. (2016). Sound–meaning association biases evidenced across thousands of languages. *Proceedings of the National Academy of Sciences*, 113(39), 10818–10823.

Chomsky, N. (1965). *Aspects of the theory of syntax.* MIT Press.

Dingemanse, M. (2012). Advances in the cross-linguistic study of ideophones. *Language and Linguistics Compass*, 6, 654–672.

Dingemanse, M., Blasi, D. E., Lupyan, G., Christiansen, M. H., & Monaghan, P. (2015). Arbitrariness, iconicity, and systematicity in language. *Trends in Cognitive Sciences*, 19(10), 603–615.

Dryer, M. S., & Haspelmath, M. (Eds.). (2013). *WALS Online.* Max Planck Institute for Evolutionary Anthropology. https://wals.info/

Erben Johansson, N., Anikin, A., Carling, G., & Holmer, A. (2020). The typology of sound symbolism: Defining macro-concepts via their semantic and phonetic features. *Linguistic Typology*, 24(2), 253–310.

Everett, C., Blasi, D. E., & Roberts, S. G. (2015). Climate, vocal folds, and tonal languages: Connecting the physiological and geographic dots. *Proceedings of the National Academy of Sciences*, 112(5), 1322–1327.

Forkel, R., et al. (2018). Cross-Linguistic Data Formats, advancing data sharing and re-use in comparative linguistics. *Scientific Data*, 5, 180205.

Gentner, D., & Goldin-Meadow, S. (Eds.). (2003). *Language in mind: Advances in the study of language and thought.* MIT Press.

Greenberg, J. H. (1963). Some universals of grammar with particular reference to the order of meaningful elements. In J. H. Greenberg (Ed.), *Universals of language* (pp. 73–113). MIT Press.

Hockett, C. F. (1960). The origin of speech. *Scientific American*, 203, 88–96.

Jablonski, N. G., & Chaplin, G. (2000). The evolution of human skin coloration. *Journal of Human Evolution*, 39(1), 57–106.

Köhler, W. (1929). *Gestalt Psychology.* Liveright.

List, J.-M., et al. (2022). Lexibank, a public repository of standardized wordlists with computed phonological and lexical features. *Scientific Data*, 9, 316.

Maddieson, I., & Coupé, C. (2015). Human spoken language diversity and the acoustic adaptation hypothesis. *The Journal of the Acoustical Society of America*, 138(3), 1838.

Nyholt, D. R. (2004). A simple correction for multiple testing for single-nucleotide polymorphisms in linkage disequilibrium with each other. *American Journal of Human Genetics*, 74(4), 765–769.

Ohala, J. J. (1994). The frequency code underlies the sound-symbolic use of voice pitch. In L. Hinton, J. Nichols, & J. J. Ohala (Eds.), *Sound symbolism* (pp. 325–347). Cambridge University Press.

Perlman, M., & Lupyan, G. (2018). People can create iconic vocalizations to communicate various meanings to naïve listeners. *Scientific Reports*, 8, 2634.

Ramachandran, V. S., & Hubbard, E. M. (2001). Synaesthesia — A window into perception, thought and language. *Journal of Consciousness Studies*, 8(12), 3–34.

Sapir, E. (1921). *Language: An introduction to the study of speech.* Harcourt, Brace & Co.

Sapir, E. (1929). A study in phonetic symbolism. *Journal of Experimental Psychology*, 12, 225–239.

Saussure, F. de. (1916). *Cours de linguistique générale.* Payot.

Skirgård, H., et al. (2023). Grambank reveals the importance of genealogical constraints on linguistic diversity and highlights the impact of language loss. *Science Advances*, 9(16), eadg6175.

Taub, S. F. (2001). *Language from the body: Iconicity and metaphor in American Sign Language.* Cambridge University Press.

Whorf, B. L. (1956). *Language, thought, and reality.* MIT Press.

Wichmann, S., Holman, E. W., & Brown, C. H. (2010). Sound symbolism in basic vocabulary. *Entropy*, 12, 844–858.

Wichmann, S., et al. (2022). The ASJP Database (version 21).

Winter, B., Perlman, M., Perry, L. K., & Lupyan, G. (2017). Which words are most iconic? Iconicity in English sensory words. *Interaction Studies*, 18(3), 443–464.

Wolff, P., & Holmes, K. J. (2011). Linguistic relativity. *WIREs Cognitive Science*, 2(3), 253–265.

---

## Data and Code Availability

All analysis code and processed data are available at: [repository URL to be added]

Raw data sources:
- ASJP Database v21: https://asjp.clld.org/
- Lexibank: https://github.com/lexibank/lexibank-analysed
- Grambank: https://github.com/grambank/grambank
- WALS Online: https://wals.info/

---

## Acknowledgments

[To be added]
